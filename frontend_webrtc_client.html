<!DOCTYPE html>
<html>
<head>
    <title>Voice AI Assistant (WebRTC)</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; background-color: #f4f4f9; }
        .container { max-width: 800px; margin: auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); }
        h1 { color: #333; text-align: center; }
        .control-panel { display: flex; justify-content: space-around; margin-top: 20px; }
        button { padding: 10px 20px; font-size: 16px; cursor: pointer; border: none; border-radius: 5px; transition: background-color 0.3s; }
        #startBtn { background-color: #28a745; color: white; }
        #startBtn:hover { background-color: #218838; }
        #stopBtn, #cancelBtn { background-color: #dc3545; color: white; }
        #stopBtn:hover, #cancelBtn:hover { background-color: #c82333; }
        #cancelBtn { display: none; }
        .result-panel { margin-top: 20px; padding: 15px; border: 1px solid #ccc; border-radius: 5px; background-color: #fff; }
        #logArea { height: 200px; overflow-y: scroll; border: 1px solid #eee; padding: 10px; margin-top: 10px; font-size: 14px; background-color: #f9f9f9; }
        .log-error { color: red; }
        .log-status { color: blue; }
        .log-response { color: darkgreen; font-weight: bold; }
        audio { width: 100%; margin-top: 10px; }
        input[type="text"] { width: 100%; padding: 8px; margin-bottom: 10px; box-sizing: border-box; border: 1px solid #ccc; border-radius: 4px; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Voice AI Assistant</h1>
        
        <input type="text" id="apiKeyInput" placeholder="Nh·∫≠p API Key (N·∫øu c·∫ßn)" />

        <div class="control-panel">
            <button id="startBtn" disabled>üé§ B·∫Øt ƒë·∫ßu Ghi √Çm</button>
            <button id="stopBtn" disabled>‚èπÔ∏è D·ª´ng & X·ª≠ L√Ω</button>
            <button id="cancelBtn">‚ùå H·ªßy X·ª≠ L√Ω</button>
        </div>

        <div class="result-panel">
            <h2>Tr·∫°ng th√°i: <span id="statusText" class="log-status">ƒêang kh·ªüi t·∫°o...</span></h2>
            <p><strong>ASR (B·∫°n n√≥i):</strong> <span id="asrText">...</span></p>
            <p><strong>Ph·∫£n h·ªìi (AI):</strong> <span id="responseText">...</span></p>
            <audio id="ttsAudio" controls autoplay></audio>
        </div>
        
        <h2>Log S·ª± Ki·ªán</h2>
        <div id="logArea"></div>
    </div>

    <script>
        // =====================================================
        // GLOBAL VARIABLES
        // =====================================================
        let pc = null;
        let localStream = null;
        let dataChannel = null;
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const cancelBtn = document.getElementById('cancelBtn');
        const apiKeyInput = document.getElementById('apiKeyInput');
        const statusText = document.getElementById('statusText');
        const asrText = document.getElementById('asrText');
        const responseText = document.getElementById('responseText');
        const ttsAudio = document.getElementById('ttsAudio');
        const logArea = document.getElementById('logArea');
        
        // =====================================================
        // UTILITY FUNCTIONS
        // =====================================================
        function log(message, type = 'default') {
            const time = new Date().toLocaleTimeString();
            const logEntry = document.createElement('div');
            logEntry.innerHTML = `[${time}] ${message}`;
            
            if (type === 'error') logEntry.classList.add('log-error');
            else if (type === 'status') logEntry.classList.add('log-status');
            else if (type === 'response') logEntry.classList.add('log-response');

            logArea.appendChild(logEntry);
            logArea.scrollTop = logArea.scrollHeight; // Auto-scroll to bottom
        }

        function updateStatus(message, isProcessing) {
            statusText.textContent = message;
            statusText.style.color = isProcessing ? 'orange' : 'blue';
            if (isProcessing) {
                responseText.textContent = 'ƒêang x·ª≠ l√Ω...';
            }
        }
        
        function updateUI(isRecording) {
            startBtn.disabled = isRecording;
            stopBtn.disabled = !isRecording;
            cancelBtn.style.display = 'none'; // Ch·ªâ hi·ªán cancel khi x·ª≠ l√Ω b·∫Øt ƒë·∫ßu
            if (isRecording) {
                asrText.textContent = 'ƒêang l·∫Øng nghe...';
                responseText.textContent = '...';
                ttsAudio.removeAttribute('src');
                updateStatus('ƒêang ghi √¢m.', true);
            } else {
                updateStatus('S·∫µn s√†ng.', false);
            }
        }
        
        // =====================================================
        // WEB RTC LOGIC
        // =====================================================
        
        async function createPeerConnection() {
            if (pc) {
                // ƒê√≥ng k·∫øt n·ªëi c≈© n·∫øu c√≥
                try { await pc.close(); } catch (e) {}
            }
            
            pc = new RTCPeerConnection();
            
            // 1. G√°n s·ª± ki·ªán Data Channel
            dataChannel = pc.createDataChannel("data-channel");
            dataChannel.onopen = () => {
                log("Data Channel ƒë√£ m·ªü.");
            };
            dataChannel.onmessage = handleDataChannelMessage;
            dataChannel.onclose = () => {
                log("Data Channel ƒë√£ ƒë√≥ng.");
                // N·∫øu data channel ƒë√≥ng m√† PC kh√¥ng ƒë√≥ng, x·ª≠ l√Ω k·∫øt th√∫c
                if (pc && pc.connectionState !== 'closed') {
                     log("PC v·∫´n m·ªü, t·∫Øt PC.", 'status');
                     pc.close();
                }
            };

            // 2. Th√™m Media Track (Audio)
            localStream.getTracks().forEach(track => {
                pc.addTrack(track, localStream);
                log(`Th√™m track: ${track.kind}`);
            });

            // 3. X·ª≠ l√Ω Candidate v√† Negotiation
            pc.onicecandidate = ({ candidate }) => {
                if (candidate) {
                    // C·∫ßn c√≥ logic ƒë·ªÉ g·ª≠i candidate n·∫øu b·∫°n mu·ªën h·ªó tr·ª£ NAT traversal
                    // Hi·ªán t·∫°i b·ªè qua v√¨ client/server c√πng localhost
                }
            };

            pc.oniceconnectionstatechange = () => {
                log(`Tr·∫°ng th√°i ICE: ${pc.iceConnectionState}`);
            };

            pc.onconnectionstatechange = () => {
                log(`Tr·∫°ng th√°i k·∫øt n·ªëi: ${pc.connectionState}`);
                if (pc.connectionState === 'closed' || pc.connectionState === 'failed') {
                    // ‚úÖ FIX: ƒê·∫£m b·∫£o UI ƒë∆∞·ª£c c·∫≠p nh·∫≠t khi k·∫øt n·ªëi ƒë√≥ng
                    if (stopBtn.disabled === false) { 
                        log('K·∫øt n·ªëi WebRTC b·ªã ƒë√≥ng b·∫•t ng·ªù.', 'error');
                        updateUI(false);
                    }
                }
            };
            
            // 4. T·∫°o Offer v√† G·ª≠i Offer ƒë·∫øn Backend
            const offer = await pc.createOffer();
            await pc.setLocalDescription(offer);
            
            log("G·ª≠i Offer ƒë·∫øn Backend...");
            const response = await fetch('/offer', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ 
                    sdp: pc.localDescription.sdp, 
                    type: pc.localDescription.type,
                    api_key: apiKeyInput.value.trim() 
                })
            });

            if (!response.ok) {
                log(`L·ªói t·ª´ Backend: ${response.statusText}`, 'error');
                stopRecording(); // T·ª± ƒë·ªông ƒë√≥ng k·∫øt n·ªëi
                return;
            }

            const answer = await response.json();
            await pc.setRemoteDescription(new RTCSessionDescription(answer));
            
            log("WebRTC Answer ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω. B·∫Øt ƒë·∫ßu ghi √¢m.");
            updateUI(true);
        }
        
        function handleDataChannelMessage(event) {
            try {
                const data = JSON.parse(event.data);
                
                if (data.type === 'metadata') {
                    if (data.status === 'ASR_COMPLETE') {
                        asrText.textContent = data.transcript;
                        log(`[ASR] Ho√†n t·∫•t: ${data.transcript}`, 'status');
                        cancelBtn.style.display = 'inline-block'; // C√≥ th·ªÉ h·ªßy x·ª≠ l√Ω DM/TTS
                        updateStatus('ƒêang x·ª≠ l√Ω DM/TTS...', true);
                    } else if (data.status === 'DM_COMPLETE') {
                        responseText.textContent = data.response_text;
                        log(`[DM] Ph·∫£n h·ªìi: ${data.response_text}`, 'response');
                        cancelBtn.style.display = 'none';
                    } else if (data.status === 'TTS_START') {
                         log('[TTS] B·∫Øt ƒë·∫ßu streaming audio.', 'status');
                    } else if (data.status === 'TTS_END') {
                         log('[TTS] K·∫øt th√∫c streaming audio.', 'status');
                    }
                } else if (data.type === 'audio_chunk') {
                    // X·ª≠ l√Ω chunk audio (Base64)
                    playAudioChunk(data.chunk);
                } else if (data.type === 'cancelled') {
                    log('X·ª≠ l√Ω ƒë√£ b·ªã H·ª¶Y b·ªüi Backend.', 'error');
                    updateUI(false);
                } else if (data.type === 'error') {
                    log(`L·ªñI X·ª≠ L√Ω: ${data.message}`, 'error');
                    updateUI(false);
                }

            } catch (e) {
                // Log n·∫øu kh√¥ng ph·∫£i JSON (c√≥ th·ªÉ l√† chunk audio th√¥)
                // Hi·ªán t·∫°i ta d√πng JSON {"type": "audio_chunk", "chunk": "..."}
                log(`L·ªói x·ª≠ l√Ω DataChannel: ${e.message}`, 'error');
            }
        }
        
        const audioQueue = [];
        let isPlaying = false;

        function playAudioChunk(base64Chunk) {
            audioQueue.push(base64Chunk);
            if (!isPlaying) {
                processQueue();
            }
        }

        async function processQueue() {
            if (audioQueue.length === 0) {
                isPlaying = false;
                return;
            }

            isPlaying = true;
            const chunk = audioQueue.shift();
            
            // Chuy·ªÉn Base64 th√†nh Blob
            const binaryString = atob(chunk);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            const blob = new Blob([bytes.buffer], { type: 'audio/wav' });

            const audioUrl = URL.createObjectURL(blob);
            
            // T·∫°m th·ªùi d√πng Audio Element ƒë·ªÉ ph√°t. 
            // C·∫ßn d√πng Web Audio API ƒë·ªÉ ph√°t tr√¥i ch·∫£y h∆°n n·∫øu c√≥ ƒë·ªô tr·ªÖ l·ªõn.
            const audio = new Audio(audioUrl);
            audio.play();

            audio.onended = () => {
                URL.revokeObjectURL(audioUrl); // Gi·∫£i ph√≥ng b·ªô nh·ªõ
                processQueue(); // Ph√°t chunk ti·∫øp theo
            };
            audio.onerror = (e) => {
                log(`L·ªói ph√°t audio: ${e.message}`, 'error');
                URL.revokeObjectURL(audioUrl);
                processQueue();
            };
        }


        function sendCancelMessage() {
            if (dataChannel && dataChannel.readyState === 'open') {
                const cancelMessage = JSON.stringify({ type: 'cancel_processing' });
                dataChannel.send(cancelMessage);
                log("ƒê√£ g·ª≠i l·ªánh H·ª¶Y x·ª≠ l√Ω.", 'status');
                cancelBtn.style.display = 'none';
            }
        }

        // ‚úÖ FIX L·ªñI TREO: ƒê·∫£m b·∫£o ƒë√≥ng PC v√† Track ƒë·ªÉ g·ª≠i t√≠n hi·ªáu d·ª´ng
        async function stopRecording() {
            if (!pc || pc.connectionState === 'closed') return;

            log("ƒêang ƒë√≥ng k·∫øt n·ªëi WebRTC...", 'status');
            
            // 1. T·∫Øt t·∫•t c·∫£ c√°c track
            if (localStream) {
                 localStream.getTracks().forEach(track => track.stop());
            }

            // 2. ƒê√≥ng Peer Connection (B·∫Øt bu·ªôc ƒë·ªÉ g·ª≠i t√≠n hi·ªáu d·ª´ng)
            try {
                pc.close();
            } catch (e) {
                log(`L·ªói khi ƒë√≥ng PC: ${e.message}`, 'error');
            }

            // 3. C·∫≠p nh·∫≠t UI
            updateUI(false);
            pc = null;
        }

        async function init() {
            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                try {
                    localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    log('Truy c·∫≠p Micro th√†nh c√¥ng.', 'status');
                    startBtn.disabled = false;
                    stopBtn.disabled = true;
                } catch (e) {
                    log(`L·ªói truy c·∫≠p Micro: ${e.message}`, 'error');
                    alert("Kh√¥ng th·ªÉ truy c·∫≠p Micro. Vui l√≤ng c·∫•p quy·ªÅn.");
                }
            } else {
                log('WebRTC kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£ tr√™n tr√¨nh duy·ªát n√†y.', 'error');
                alert("Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ WebRTC.");
            }
        }

        // =====================================================
        // EVENT LISTENERS
        // =====================================================
        startBtn.addEventListener('click', async () => {
             if (!localStream) {
                 await init();
             }
             if (localStream) {
                 createPeerConnection();
             }
        });
        
        // G√°n s·ª± ki·ªán cho n√∫t D·ª´ng Ghi √Çm
        stopBtn.addEventListener('click', stopRecording); 

        // G√°n s·ª± ki·ªán cho n√∫t H·ªßy X·ª≠ L√Ω
        cancelBtn.addEventListener('click', sendCancelMessage);
        
        // Kh√¥i ph·ª•c/L∆∞u API Key t·ª´ Local Storage
        window.onload = function() {
            const savedKey = localStorage.getItem('voice_ai_api_key');
            if (savedKey) {
                apiKeyInput.value = savedKey;
            } 
            init(); // Kh·ªüi t·∫°o Micro khi t·∫£i trang
        };

        apiKeyInput.addEventListener('change', () => {
            const key = apiKeyInput.value.trim();
            localStorage.setItem('voice_ai_api_key', key);
            log("API Key ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°m th·ªùi.", 'status');
        });

    </script>
</body>
</html>