<!DOCTYPE html>
<html>
<head>
    <title>Voice AI Assistant (WebRTC)</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; background-color: #f4f4f9; }
        .container { max-width: 800px; margin: auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); }
        h1 { color: #333; text-align: center; }
        .control-panel { display: flex; justify-content: space-around; margin-top: 20px; }
        button { padding: 10px 20px; font-size: 16px; cursor: pointer; border: none; border-radius: 5px; transition: background-color 0.3s; }
        #startBtn { background-color: #28a745; color: white; }
        #startBtn:hover { background-color: #218838; }
        #stopBtn, #cancelBtn { background-color: #dc3545; color: white; }
        #stopBtn:hover, #cancelBtn:hover { background-color: #c82333; }
        #cancelBtn { display: none; }
        .result-panel { margin-top: 20px; padding: 15px; border: 1px solid #ccc; border-radius: 5px; background-color: #fff; }
        #log { margin-top: 15px; padding: 10px; background-color: #e9ecef; border-radius: 4px; max-height: 200px; overflow-y: auto; font-size: 0.9em; }
        #status { text-align: center; font-weight: bold; margin-top: 10px; color: #007bff; }
        #progressContainer { margin-top: 20px; }
        progress { width: 100%; height: 25px; }
        .text-output { margin-top: 10px; padding: 10px; border: 1px dashed #007bff; border-radius: 5px; }
        .user-text, .bot-text { margin-bottom: 5px; }
        .user-text { color: #343a40; }
        .bot-text { color: #007bff; font-weight: bold; }
        .api-key-panel { margin-top: 20px; padding: 10px; background-color: #f8d7da; border: 1px solid #f5c6cb; border-radius: 5px; }
        .audio-source-panel { margin-top: 20px; padding: 10px; border: 1px solid #ccc; border-radius: 5px; background-color: #f9f9f9; }
        .audio-source-panel label { margin-right: 15px; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Voice AI Assistant (WebRTC)</h1>

        <div class="api-key-panel">
            <label for="apiKeyInput">API Key (Mocked for Demo):</label>
            <input type="text" id="apiKeyInput" placeholder="Nh·∫≠p API Key (Kh√¥ng b·∫Øt bu·ªôc trong demo n√†y)" style="width: 100%;">
        </div>

        <div class="audio-source-panel">
            <h2>Ch·ªçn ngu·ªìn Audio:</h2>
            <label><input type="radio" name="audioSource" value="mic" checked> Microphone</label>
            <label><input type="radio" name="audioSource" value="system"> √Çm thanh H·ªá th·ªëng (C·∫ßn Chia s·∫ª M√†n h√¨nh)</label>
        </div>

        <div class="control-panel">
            <button id="startBtn">‚ñ∂Ô∏è B·∫Øt ƒê·∫ßu Ghi √Çm</button>
            <button id="stopBtn" disabled>‚èπÔ∏è D·ª´ng & X·ª≠ L√Ω</button>
            <button id="cancelBtn">‚ùå H·ªßy X·ª≠ L√Ω</button>
        </div>

        <div id="status">ƒêang ch·ªù k·∫øt n·ªëi...</div>

        <div id="progressContainer">
            <progress id="progressBar" value="0" max="100"></progress>
        </div>

        <div class="result-panel">
            <h2>K·∫øt Qu·∫£:</h2>
            <div id="textOutput" class="text-output">
                <div class="user-text"><strong>Ng∆∞·ªùi d√πng:</strong> </div>
                <div class="bot-text"><strong>Bot:</strong> </div>
            </div>
            <audio id="ttsAudio" controls autoplay style="width: 100%; margin-top: 10px;"></audio>
            <div id="log"></div>
        </div>
    </div>

    <script>
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const cancelBtn = document.getElementById('cancelBtn');
        const statusDiv = document.getElementById('status');
        const logDiv = document.getElementById('log');
        const textOutputDiv = document.getElementById('textOutput');
        const ttsAudio = document.getElementById('ttsAudio');
        const progressBar = document.getElementById('progressBar');
        const apiKeyInput = document.getElementById('apiKeyInput');
        
        // Ngu·ªìn Audio Selection
        const audioSourceRadios = document.querySelectorAll('input[name="audioSource"]');


        let pc = null;
        let dataChannel = null;
        let localStream = null;
        let sessionId = null;
        let ws = null;

        // ======================================================
        // C√ÅC H√ÄM TI·ªÜN √çCH
        // ======================================================
        function log(message, type = 'info') {
            const time = new Date().toLocaleTimeString();
            logDiv.innerHTML = `<span style="color: ${type === 'error' ? 'red' : type === 'status' ? 'green' : 'black'};">[${time}] ${message}</span><br>` + logDiv.innerHTML;
        }

        function updateStatus(message, progressValue = 0) {
            statusDiv.textContent = message;
            progressBar.value = progressValue;
        }

        function resetUI(fullReset = false) {
            startBtn.disabled = false;
            stopBtn.disabled = true;
            cancelBtn.style.display = 'none';
            if (fullReset) {
                 updateStatus('S·∫µn s√†ng cho phi√™n m·ªõi.', 0);
                 textOutputDiv.querySelector('.user-text').innerHTML = '<strong>Ng∆∞·ªùi d√πng:</strong> ';
                 textOutputDiv.querySelector('.bot-text').innerHTML = '<strong>Bot:</strong> ';
            }
        }

        // ======================================================
        // WEBSOCKET (cho ICE Candidates)
        // ======================================================
        function initWebSocket(pc, newSessionId) {
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.close();
            }
            
            sessionId = newSessionId;
            const wsUrl = `ws://${window.location.host}/ws?session_id=${sessionId}`;
            ws = new WebSocket(wsUrl);

            ws.onopen = () => {
                log('WebSocket ƒë√£ k·∫øt n·ªëi th√†nh c√¥ng.', 'status');
                pc.onicecandidate = ({ candidate }) => {
                    if (candidate) {
                        log(`[WebRTC] Nh·∫≠n ICE Candidate: ${candidate.type}`);
                    } else {
                        log('[WebRTC] Ho√†n t·∫•t thu th·∫≠p ICE Candidates.');
                    }
                };
            };

            ws.onclose = () => {
                log('WebSocket ƒë√£ ƒë√≥ng.', 'status');
            };

            ws.onerror = (error) => {
                log(`L·ªói WebSocket: ${error}`, 'error');
            };
        }
        
        // ======================================================
        // PEER CONNECTION V√Ä SIGNALLING
        // ======================================================
        async function createPeerConnection() {
            if (!localStream || localStream.getAudioTracks().length === 0) {
                 log('‚ùå Kh√¥ng c√≥ lu·ªìng audio h·ª£p l·ªá ƒë·ªÉ b·∫Øt ƒë·∫ßu.', 'error');
                 alert('Kh√¥ng c√≥ lu·ªìng audio h·ª£p l·ªá ƒë·ªÉ b·∫Øt ƒë·∫ßu ghi √¢m. Vui l√≤ng c·∫•p quy·ªÅn Microphone ho·∫∑c ch·ªçn √Çm thanh H·ªá th·ªëng.');
                 return;
            }

            if (pc && pc.connectionState !== 'closed') {
                try {
                    await pc.close();
                    log('[WebRTC] ƒê√£ ƒë√≥ng Peer Connection c≈©.');
                } catch (e) {
                     log(`[WebRTC] L·ªói khi ƒë√≥ng PC c≈©: ${e.message}`, 'error');
                }
            }
            
            sessionId = crypto.randomUUID();
            pc = new RTCPeerConnection();
            
            // 1. Kh·ªüi t·∫°o WebSocket cho phi√™n m·ªõi
            initWebSocket(pc, sessionId); 
            
            pc.onconnectionstatechange = () => {
                log(`[WebRTC] Tr·∫°ng th√°i k·∫øt n·ªëi: ${pc.connectionState}`);
                if (pc.connectionState === 'disconnected' || pc.connectionState === 'failed') {
                    log('[WebRTC] K·∫øt n·ªëi b·ªã ng·∫Øt ho·∫∑c th·∫•t b·∫°i.', 'error');
                    resetUI(true);
                } else if (pc.connectionState === 'closed') {
                     log('[WebRTC] K·∫øt n·ªëi ƒë√£ ƒë√≥ng.', 'status');
                     resetUI(true);
                }
            };

            // 2. Th√™m MediaStreamTrack (audio) t·ª´ microphone/h·ªá th·ªëng
            localStream.getTracks().forEach(track => {
                 pc.addTrack(track, localStream);
                 log(`[WebRTC] ƒê√£ th√™m track ${track.kind} v√†o Peer Connection.`);
            });
            
            // 3. T·∫°o Data Channel cho tin nh·∫Øn ƒëi·ªÅu khi·ªÉn
            dataChannel = pc.createDataChannel("chat");
            dataChannel.onopen = () => {
                log('[DataChannel] ƒê√£ m·ªü Data Channel.', 'status');
                startBtn.disabled = true;
                stopBtn.disabled = false;
                updateStatus('üîä ƒêang Ghi √Çm...', 5);
                cancelBtn.style.display = 'none'; // Ch·ªâ hi·ªÉn th·ªã khi ƒëang x·ª≠ l√Ω
            };

            dataChannel.onmessage = handleDataChannelMessage;
            dataChannel.onclose = () => log('[DataChannel] ƒê√£ ƒë√≥ng Data Channel.');

            // 4. T·∫°o Offer v√† g·ª≠i ƒë·∫øn Backend
            const offer = await pc.createOffer();
            await pc.setLocalDescription(offer);
            
            updateStatus('ƒêang thi·∫øt l·∫≠p k·∫øt n·ªëi WebRTC...', 10);
            log(`[WebRTC] ƒê√£ g·ª≠i SDP Offer ƒë·∫øn Server. Session ID: ${sessionId}`);

            try {
                const response = await fetch('/offer', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        sdp: pc.localDescription.sdp,
                        type: pc.localDescription.type,
                        session_id: sessionId
                    })
                });
                
                if (!response.ok) throw new Error('Server returned non-ok status');

                const answer = await response.json();
                await pc.setRemoteDescription(new RTCSessionDescription(answer));
                updateStatus('ƒê√£ thi·∫øt l·∫≠p k·∫øt n·ªëi WebRTC. S·∫µn s√†ng ghi √¢m.', 20);

            } catch (e) {
                log(`L·ªói Signalling/Offer: ${e.message}`, 'error');
                updateStatus('‚ùå L·ªói k·∫øt n·ªëi Server.', 0);
                try { await pc.close(); } catch {}
            }
        }
        
        function handleDataChannelMessage(event) {
            try {
                const data = JSON.parse(event.data);
                
                if (data.type === 'start_processing') {
                    updateStatus('üß† Server ƒëang X·ª≠ l√Ω ASR & NLU...', 40);
                    stopBtn.disabled = true;
                    cancelBtn.style.display = 'inline-block';
                    ttsAudio.removeAttribute('src');
                    ttsAudio.pause();

                } else if (data.type === 'text_response') {
                    updateStatus('üéµ Server ƒëang T·ªïng h·ª£p TTS...', 70);
                    textOutputDiv.querySelector('.user-text').innerHTML = `<strong>Ng∆∞·ªùi d√πng:</strong> ${data.user_text || 'Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c gi·ªçng n√≥i.'}`;
                    textOutputDiv.querySelector('.bot-text').innerHTML = `<strong>Bot:</strong> ${data.bot_text}`;

                } else if (data.type === 'audio_chunk') {
                    appendAudioChunk(data.chunk);

                } else if (data.type === 'end_of_session') {
                    updateStatus('‚úÖ X·ª≠ l√Ω ho√†n t·∫•t. ƒêang ph√°t audio...', 100);
                    finalizeAudio();
                    
                } else if (data.type === 'error') {
                    log(`L·ªñI X·ª¨ L√ù SERVER: ${data.error}`, 'error');
                    updateStatus('‚ùå L·ªói Server. Vui l√≤ng th·ª≠ l·∫°i.', 0);
                    resetUI(true);
                }

            } catch (e) {
                log(`L·ªói ph√¢n t√≠ch JSON t·ª´ Data Channel: ${e.message}`, 'error');
            }
        }
        
        // ======================================================
        // X·ª¨ L√ù AUDIO TTS
        // ======================================================
        let audioChunks = [];
        let audioMimeType = 'audio/wav'; 

        function appendAudioChunk(chunk) {
            audioChunks.push(atob(chunk)); 
        }

        function finalizeAudio() {
            if (audioChunks.length === 0) {
                 log('[TTS] Kh√¥ng nh·∫≠n ƒë∆∞·ª£c audio chunks.', 'error');
                 resetUI(true);
                 return;
            }
            
            const rawData = audioChunks.join('');
            const buffer = new Uint8Array(rawData.length);
            for (let i = 0; i < rawData.length; i++) {
                buffer[i] = rawData.charCodeAt(i);
            }
            
            const blob = new Blob([buffer], { type: audioMimeType });
            const audioUrl = URL.createObjectURL(blob);
            
            ttsAudio.src = audioUrl;
            ttsAudio.play().catch(e => log(`L·ªói khi ph√°t audio: ${e.message} (C√≥ th·ªÉ tr√¨nh duy·ªát c·∫ßn t∆∞∆°ng t√°c ng∆∞·ªùi d√πng)`, 'error'));
            
            audioChunks = []; 
            // KH√îNG reset UI ·ªü ƒë√¢y, ƒë·ª£i onended ƒë·ªÉ tr√°nh ng·∫Øt ti·∫øng ph√°t d·ªü
        }

        // ======================================================
        // C√ÅC H√ÄM ƒêI·ªÄU KHI·ªÇN
        // ======================================================
        async function stopRecording() {
            if (pc && pc.connectionState === 'connected') {
                updateStatus('ƒêang k·∫øt th√∫c ghi √¢m v√† g·ª≠i l·ªánh x·ª≠ l√Ω...', 30);
                stopBtn.disabled = true;
                startBtn.disabled = true; 
                
                // G·ª≠i l·ªánh D·ª™NG GHI √ÇM ƒë·∫øn Backend qua Data Channel
                if (dataChannel && dataChannel.readyState === 'open') {
                    dataChannel.send(JSON.stringify({ type: 'stop_recording' }));
                    log('[DataChannel] ƒê√£ g·ª≠i l·ªánh D·ª™NG GHI √ÇM.');
                }
            }
        }
        
        function sendCancelMessage() {
            if (pc && pc.connectionState === 'connected' && dataChannel && dataChannel.readyState === 'open') {
                dataChannel.send(JSON.stringify({ type: 'cancel_processing' }));
                log('[DataChannel] ƒê√£ g·ª≠i l·ªánh H·ª¶Y X·ª¨ L√ù.', 'error');
                updateStatus('ƒê√£ h·ªßy x·ª≠ l√Ω.', 0);
                resetUI(true);
                if (ttsAudio.src) { ttsAudio.pause(); ttsAudio.removeAttribute('src'); }
            }
        }

        // ======================================================
        // KH·ªûI T·∫†O MICROPHONE/SYSTEM AUDIO (ƒê√É S·ª¨A ƒê·ªîI)
        // ======================================================
        async function initStream(force = false) {
            const selectedSource = document.querySelector('input[name="audioSource"]:checked').value;

            // N·∫øu stream ƒë√£ t·ªìn t·∫°i v√† ƒë√∫ng ngu·ªìn, kh√¥ng c·∫ßn kh·ªüi t·∫°o l·∫°i
            if (localStream && !force) {
                let isCorrectSource = false;
                const audioTrack = localStream.getAudioTracks()[0];
                if (audioTrack) {
                    // Ki·ªÉm tra xem lu·ªìng hi·ªán t·∫°i c√≥ ph·∫£i l√† mic hay display (system audio) kh√¥ng
                    const isMic = audioTrack.label.toLowerCase().includes('mic');
                    const isDisplay = audioTrack.label.toLowerCase().includes('display') || audioTrack.label.toLowerCase().includes('system');
                    
                    if (selectedSource === 'mic' && isMic) isCorrectSource = true;
                    if (selectedSource === 'system' && isDisplay) isCorrectSource = true;
                }
                if (isCorrectSource) {
                    startBtn.disabled = false;
                    return; 
                }
            }
            
            // D·ª´ng stream c≈© n·∫øu c√≥
            if (localStream) {
                localStream.getTracks().forEach(track => track.stop());
                localStream = null;
            }

            try {
                if (selectedSource === 'mic') {
                    localStream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
                    log('‚úÖ Truy c·∫≠p Microphone th√†nh c√¥ng.', 'status');
                } else if (selectedSource === 'system') {
                    // S·ª≠ d·ª•ng getDisplayMedia ƒë·ªÉ l·∫•y lu·ªìng audio h·ªá th·ªëng
                    localStream = await navigator.mediaDevices.getDisplayMedia({ video: false, audio: true });
                    
                    const audioTrack = localStream.getAudioTracks()[0];
                    if (audioTrack) {
                         // L·∫Øng nghe s·ª± ki·ªán ng∆∞·ªùi d√πng d·ª´ng chia s·∫ª m√†n h√¨nh/audio
                         audioTrack.onended = () => {
                            log('‚ö†Ô∏è Chia s·∫ª √Çm thanh H·ªá th·ªëng ƒë√£ b·ªã d·ª´ng b·ªüi ng∆∞·ªùi d√πng/tr√¨nh duy·ªát.', 'error');
                            if (pc && pc.connectionState !== 'closed') {
                                stopRecording(); // T·ª± ƒë·ªông d·ª´ng ghi √¢m
                            }
                        };
                        log('‚úÖ Truy c·∫≠p √Çm thanh H·ªá th·ªëng th√†nh c√¥ng (Vui l√≤ng ch·ªçn "Chia s·∫ª √¢m thanh" trong h·ªôp tho·∫°i).', 'status');
                    } else {
                        log('‚ùå L·ªói: Kh√¥ng th·ªÉ l·∫•y lu·ªìng Audio t·ª´ Chia s·∫ª M√†n h√¨nh. H√£y ƒë·∫£m b·∫£o ch·ªçn "Chia s·∫ª √¢m thanh".', 'error');
                        // N·∫øu kh√¥ng l·∫•y ƒë∆∞·ª£c audio track, d·ª´ng stream
                        localStream.getTracks().forEach(track => track.stop());
                        localStream = null;
                    }
                }
                
                if (localStream && localStream.getAudioTracks().length > 0) {
                    startBtn.disabled = false;
                } else {
                    startBtn.disabled = true;
                }

            } catch (e) {
                log(`‚ùå L·ªói truy c·∫≠p Audio (${selectedSource}): ${e.name}: ${e.message}`, 'error');
                alert(`Kh√¥ng th·ªÉ truy c·∫≠p ngu·ªìn audio (${selectedSource}). Vui l√≤ng c·∫•p quy·ªÅn v√† th·ª≠ l·∫°i.`);
                startBtn.disabled = true;
            }
        }

        // ======================================================
        // EVENT LISTENERS
        // ======================================================
        startBtn.addEventListener('click', async () => {
             await initStream(true); // Kh·ªüi t·∫°o stream m·ªôt l·∫ßn n·ªØa ƒë·ªÉ ƒë·∫£m b·∫£o ngu·ªìn ƒë√∫ng
             if (localStream && localStream.getAudioTracks().length > 0) {
                 createPeerConnection(); // T·∫°o PC v√† g·ªçi initWebSocket b√™n trong
             } else {
                 log('‚ùå Vui l√≤ng ch·ªçn ngu·ªìn Audio v√† c·∫•p quy·ªÅn tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu.', 'error');
             }
        });
        
        // L·∫Øng nghe s·ª± ki·ªán thay ƒë·ªïi ngu·ªìn audio ƒë·ªÉ kh·ªüi t·∫°o l·∫°i stream
        audioSourceRadios.forEach(radio => {
            radio.addEventListener('change', () => initStream(true));
        });
        
        stopBtn.addEventListener('click', stopRecording); 

        cancelBtn.addEventListener('click', sendCancelMessage);
        
        ttsAudio.onended = () => {
             log('[TTS] K·∫øt th√∫c ph√°t audio.', 'status');
             updateStatus('ƒê√£ x·ª≠ l√Ω xong. S·∫µn s√†ng cho phi√™n m·ªõi.', 100);
             resetUI(true); 
        }

        window.onload = function() {
            const savedKey = localStorage.getItem('voice_ai_api_key');
            if (savedKey) {
                apiKeyInput.value = savedKey;
            } 
            initStream(); // Ch·ªâ init stream khi t·∫£i trang
        };

        apiKeyInput.addEventListener('change', () => {
            const key = apiKeyInput.value.trim();
            localStorage.setItem('voice_ai_api_key', key);
            log("API Key ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°m th·ªùi.", 'status');
        });
        
        // Ki·ªÉm tra tr√¨nh duy·ªát h·ªó tr·ª£
        if (!navigator.mediaDevices || !RTCPeerConnection) {
            alert("Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ WebRTC.");
        }

    </script>
</body>
</html>