# rtc_integration_layer.py - ƒê√£ t√≠ch h·ª£p ASR (Whisper Logic) v√† DialogManager
import asyncio
import os
import wave
import uuid
import time
from pathlib import Path
from typing import AsyncGenerator, Callable, Optional, Tuple, Any
from datetime import datetime as _dt
import numpy as np # C·∫ßn thi·∫øt cho Whisper
import traceback 

# --- SAFE IMPORTS (WHISPER) ---
try:
    import whisper
    # L·∫•y WHISPER_MODEL_NAME t·ª´ config_db n·∫øu c√≥
    try:
        from config_db import WHISPER_MODEL_NAME
    except ImportError:
        WHISPER_MODEL_NAME = "small"
        
    # T·∫£i model (C√ì TH·ªÇ G√ÇY L·ªñI KHI RE-LOAD V·ªöI UVICORN/MULTIPROCESSING)
    # N·∫øu server v·∫´n l·ªói, h√£y chuy·ªÉn vi·ªác t·∫£i model n√†y v√†o h√†m __init__
    WHISPER_MODEL = whisper.load_model(WHISPER_MODEL_NAME)
    print(f"‚úÖ [ASR] Whisper model '{WHISPER_MODEL_NAME}' ƒë√£ ƒë∆∞·ª£c t·∫£i.")
    WHISPER_IS_READY = True
except Exception as e:
    WHISPER_IS_READY = False
    WHISPER_MODEL = None
    print(f"‚ùå [ASR] L·ªói t·∫£i Whisper (pip install openai-whisper?): {e}. S·ª≠ d·ª•ng Mock.")

# --- SAFE IMPORTS (DIALOG MANAGER) ---
try:
    from dialog_manager import DialogManager 
    DM_IS_READY = True
except ImportError:
    class DialogManager:
        def __init__(self, *args, **kwargs): pass
        def process_audio_path(self, *args, **kwargs): 
            return {"response_text": "L·ªñI DM: Kh√¥ng t√¨m th·∫•y DialogManager.", "response_audio_path": None, "user_input_asr": "L·ªñI."}
    DM_IS_READY = False
    print("‚ùå [NLU] Kh√¥ng t√¨m th·∫•y DialogManager. S·ª≠ d·ª•ng Mock Fallback.")

# --- H·∫±ng s·ªë (Ph·∫£i kh·ªõp v·ªõi config_db.py) ---
SAMPLE_RATE = 16000 
CHANNELS = 1
CHUNK_SIZE = 1024 
RECORDING_DIR = Path("rtc_recordings"); RECORDING_DIR.mkdir(exist_ok=True) 

# ==================== C√ÅC D·ªäCH V·ª§ ASR ====================

class ASRServiceWhisper:
    """ASR s·ª≠ d·ª•ng OpenAI Whisper, x·ª≠ l√Ω file WAV ƒë√£ l∆∞u."""
    def __init__(self, log_callback: Callable, model):
        self._log = log_callback 
        self.model = model
        
    async def transcribe(self, audio_filepath: Path) -> AsyncGenerator[str, None]:
        self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üéôÔ∏è [ASR] B·∫Øt ƒë·∫ßu x·ª≠ l√Ω Whisper tr√™n file: {audio_filepath.name}", color="blue")

        if not WHISPER_IS_READY:
            self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üéôÔ∏è [ASR] Whisper kh√¥ng s·∫µn s√†ng. Gi·∫£ l·∫≠p transcript.", color="red")
            yield "ƒê√¢y l√† transcript gi·∫£ l·∫≠p khi Whisper l·ªói"
            return
            
        try:
            audio = whisper.load_audio(str(audio_filepath))
            
            # S·ª≠ d·ª•ng asyncio.to_thread ƒë·ªÉ ch·∫°y Whisper (t√°c v·ª• Blocking I/O)
            result = await asyncio.to_thread(self.model.transcribe, audio)
            final_transcript = result.get("text", "").strip()
            
            self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üéôÔ∏è [ASR] Transcript: '{final_transcript}'", color="blue")
            
            yield final_transcript
            
        except Exception as e:
            self._log(f"[{_dt.now().strftime('%H:%M:%S')}] ‚ùå [ASR] L·ªñI WHISPER: {e}", color="red")
            # In traceback chi ti·∫øt n·∫øu l·ªói
            self._log(traceback.format_exc(), color="red")
            yield "" 

class ASRServiceMock:
    """Gi·∫£ l·∫≠p d·ªãch v·ª• ASR."""
    def __init__(self, log_callback: Callable):
        self._log = log_callback 
        self.full_transcript = "Xin cho t√¥i ƒë·∫∑t m·ªôt ƒë∆°n h√†ng cu·ªëi c√πng" 

    async def transcribe(self, audio_filepath: Path) -> AsyncGenerator[str, None]:
        self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üéôÔ∏è [ASR MOCK] B·∫Øt ƒë·∫ßu x·ª≠ l√Ω lu·ªìng √¢m thanh...", color="blue")
        
        await asyncio.sleep(0.5) 
        
        transcript = self.full_transcript
        for i, word in enumerate(transcript.split()):
            yield word + (" " if i < len(transcript.split()) - 1 else "")
            
# ==================== D·ªäCH V·ª§ TTS (V·∫´n l√† Mock) ====================

class TTSServiceMock:
    """Gi·∫£ l·∫≠p d·ªãch v·ª• TTS, nh·∫≠n text v√† tr·∫£ v·ªÅ lu·ªìng audio (bytes)."""
    def __init__(self, log_callback: Callable):
        self._log = log_callback
        
    async def synthesize_stream(self, text: str) -> AsyncGenerator[bytes, None]:
        self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üéµ [TTS MOCK] B·∫Øt ƒë·∫ßu t·ªïng h·ª£p √¢m thanh cho: '{text[:30]}...'", color="magenta")
        
        mock_chunk_size = 320 
        mock_chunk = os.urandom(mock_chunk_size) 
        num_chunks = int(len(text) * 0.5) + 10 
        num_chunks = max(30, min(100, num_chunks)) 
        
        for _ in range(num_chunks):
            yield mock_chunk
            await asyncio.sleep(0.005) 
            
        self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üéµ [TTS MOCK] K·∫øt th√∫c lu·ªìng audio TTS ({num_chunks} chunks).", color="magenta")

# ==================== L·ªöP X·ª¨ L√ù RTC T√çCH H·ª¢P ====================

class RTCStreamProcessor:
    
    @staticmethod
    async def _record_stream(audio_input_stream: AsyncGenerator[bytes, None], record_file: Path) -> Path:
        """Ghi audio input v√†o file WAV v√† tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n file."""
        
        # CH√ö √ù: M·ªü file I/O blocking trong Async function l√† kh√¥ng n√™n, 
        # nh∆∞ng wave.open kh√¥ng c√≥ phi√™n b·∫£n async, ta ch·∫•p nh·∫≠n ƒëi·ªÅu n√†y 
        # v√¨ n√≥ ch·ªâ di·ªÖn ra m·ªôt l·∫ßn sau khi lu·ªìng k·∫øt th√∫c.
        wf = wave.open(str(record_file), 'wb')
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(2) 
        wf.setframerate(SAMPLE_RATE)
        
        # V√≤ng l·∫∑p nh·∫≠n audio chunks l√† async
        async for chunk in audio_input_stream:
            wf.writeframes(chunk) # L·ªói ·ªü ƒë√¢y s·∫Ω ƒë∆∞·ª£c b·∫Øt b·ªüi try/except b√™n ngo√†i
            
        wf.close()
        return record_file
    
    def __init__(self, log_callback: Optional[Callable] = None):
        def default_log(message, color=None):
            print(f"[{_dt.now().strftime('%H:%M:%S')}] [LOG] {message}")

        self._log = log_callback if log_callback else default_log

        if WHISPER_IS_READY:
            self._asr_client = ASRServiceWhisper(self._log, WHISPER_MODEL)
            self._asr_mode = "WHISPER"
        else:
            self._asr_client = ASRServiceMock(self._log)
            self._asr_mode = "MOCK"

        # T√≠ch h·ª£p DialogManager v√† TTS Mock
        self._dm = DialogManager(log_callback=self._log, mode="RTC") 
        self._tts_client = TTSServiceMock(self._log)

    async def handle_rtc_session(self, 
                                 audio_input_stream: AsyncGenerator[bytes, None],
                                 session_id: str) \
                                 -> AsyncGenerator[Tuple[bool, Any], None]:
        
        self._log("‚ñ∂Ô∏è [RTC] B·∫Øt ƒë·∫ßu phi√™n RTC...", color="cyan")
        
        record_file = RECORDING_DIR / f"{session_id}_input.wav"
        full_transcript = ""
        response_text = "Xin l·ªói, t√¥i ch∆∞a th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu."
        
        # ‚ö†Ô∏è KH·ªêI TRY L·ªöN: Bao b·ªçc to√†n b·ªô logic phi√™n ƒë·ªÉ ƒë·∫£m b·∫£o finally ch·∫°y
        try: 
            # 1. Ghi √¢m thanh v√†o file WAV
            try:
                # Ghi lu·ªìng audio, ƒë·ª£i cho ƒë·∫øn khi h·∫øt lu·ªìng
                await self._record_stream(audio_input_stream, record_file)
                self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üíæ [Recorder] ƒê√£ l∆∞u audio input v√†o: {record_file.name}", color="orange")
            except Exception as e:
                self._log(f"[{_dt.now().strftime('%H:%M:%S')}] ‚ùå [Recorder] L·ªói ghi file: {e}", color="red")
                # In traceback cho l·ªói I/O
                self._log(traceback.format_exc(), color="red")
                record_file = None # ƒê·∫∑t l·∫°i file th√†nh None n·∫øu c√≥ l·ªói

            # **********************************************
            # 2. X·ª≠ l√Ω ASR, NLU, TTS (Ch·ªâ ch·∫°y n·∫øu c√≥ file)
            # **********************************************
            if record_file and os.path.exists(record_file):
                # 2. X·ª≠ l√Ω ASR
                asr_stream = self._asr_client.transcribe(record_file)
                async for partial_text in asr_stream:
                     if partial_text:
                         full_transcript = partial_text

                # 3. NLU/Response Logic - T√çCH H·ª¢P DIALOG MANAGER
                if full_transcript.strip():
                    dm_result = self._dm.process_audio_path(str(record_file), user_input_asr=full_transcript)
                else:
                    dm_result = self._dm.process_audio_path(str(record_file), user_input_asr="[NO SPEECH DETECTED]")
                    dm_result['response_text'] = "Xin l·ªói, t√¥i kh√¥ng nghe r√µ. B·∫°n c√≥ th·ªÉ n√≥i l·∫°i kh√¥ng?"
                    
                response_text = dm_result.get("response_text", response_text)
                
                self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üß† [DM] Transcript: '{full_transcript[:30]}...' -> Response: '{response_text[:30]}...'", color="green")

                # YIELD TEXT METADATA ƒê·ªÇ GHI V√ÄO CHAT BOX
                yield (False, {"user_text": full_transcript, "bot_text": response_text})

                # 4. TTS v√† Tr·∫£ v·ªÅ Lu·ªìng Audio
                tts_audio_stream = self._tts_client.synthesize_stream(response_text)
                
                # YIELD AUDIO CHUNKS
                async for audio_chunk in tts_audio_stream:
                    yield (True, audio_chunk)
        
        except Exception as e:
            # B·∫Øt c√°c l·ªói kh√¥ng l∆∞·ªùng tr∆∞·ªõc x·∫£y ra trong qu√° tr√¨nh ASR/NLU/TTS
            self._log(f"[{_dt.now().strftime('%H:%M:%S')}] ‚ùå [RTC] L·ªñI X·ª¨ L√ù CHUNG: {e}", color="red")
            self._log(traceback.format_exc(), color="red")

        # ‚ö†Ô∏è KH·ªêI FINALLY: ƒê·∫£m b·∫£o lu·ªìng d·ªçn d·∫πp ch·∫°y
        finally: 
             self._log(f"[{_dt.now().strftime('%H:%M:%S')}] [RTC] K·∫øt th√∫c x·ª≠ l√Ω RTC. (File: {record_file.name if record_file else 'None'})", color="cyan")