# rtc_integration_layer.py

import asyncio
from typing import AsyncGenerator, Callable, Optional, AsyncIterator, Tuple, Any
import time
from pathlib import Path
import wave 
import uuid 
import os 
from datetime import datetime as _dt 

# --- H·∫±ng s·ªë (Ph·∫£i kh·ªõp v·ªõi main_app.py) ---
SAMPLE_RATE = 16000 
CHANNELS = 1
CHUNK_SIZE = 1024 # <-- ƒê√É TH√äM: Kh·∫Øc ph·ª•c l·ªói ImportError
# TH∆Ø M·ª§C GHI √ÇM
RECORDING_DIR = Path("rtc_recordings"); RECORDING_DIR.mkdir(exist_ok=True) 

# ==================== MOCK SERVICES (Gi·∫£ l·∫≠p ASR v√† TTS) ====================

class ASRServiceMock:
    """Gi·∫£ l·∫≠p d·ªãch v·ª• ASR, nh·∫≠n lu·ªìng audio v√† tr·∫£ v·ªÅ lu·ªìng text."""
    def __init__(self, log_callback: Callable):
        self._log = log_callback 
        self.full_transcript = "Xin cho t√¥i ƒë·∫∑t m·ªôt ƒë∆°n h√†ng cu·ªëi c√πng" 

    async def transcribe(self, audio_stream: AsyncGenerator[bytes, None]) -> AsyncGenerator[str, None]:
        """X·ª≠ l√Ω lu·ªìng audio v√† t·∫°o lu·ªìng transcript."""
        self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üéôÔ∏è [ASR] B·∫Øt ƒë·∫ßu nh·∫≠n v√† x·ª≠ l√Ω lu·ªìng √¢m thanh...", color="blue")
        
        chunk_count = 0
        async for chunk in audio_stream:
            chunk_count += 1
            pass 
        
        self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üéôÔ∏è [ASR] Nh·∫≠n {chunk_count} chunks. K·∫øt th√∫c lu·ªìng audio.", color="blue")

        if chunk_count > 0:
            await asyncio.sleep(0.01) 
            for i, word in enumerate(self.full_transcript.split()):
                yield word + (" " if i < len(self.full_transcript.split()) - 1 else "")
        else:
            yield "" 

class TTSServiceMock:
    """Gi·∫£ l·∫≠p d·ªãch v·ª• TTS, nh·∫≠n text v√† tr·∫£ v·ªÅ lu·ªìng audio."""
    def __init__(self, log_callback: Callable):
        self._log = log_callback

    async def synthesize(self, text_response: str) -> AsyncGenerator[bytes, None]:
        """T·∫°o lu·ªìng audio t·ª´ vƒÉn b·∫£n."""
        self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üîä [TTS] B·∫Øt ƒë·∫ßu t·∫°o lu·ªìng audio ph·∫£n h·ªìi...", color="purple")
        
        # Gi·∫£ l·∫≠p t·∫°o audio chunks
        audio_chunk = f"audio_chunk_for_{text_response}".encode('utf-8')
        # T·∫°o √≠t nh·∫•t 1 chunk ƒë·ªÉ ƒë·∫£m b·∫£o lu·ªìng tr·∫£ v·ªÅ
        num_chunks = max(1, len(audio_chunk) // CHUNK_SIZE + (1 if len(audio_chunk) % CHUNK_SIZE > 0 else 0))
        
        for i in range(num_chunks):
            # C·∫Øt chunk theo CHUNK_SIZE
            start_index = i * CHUNK_SIZE
            end_index = (i + 1) * CHUNK_SIZE
            chunk = audio_chunk[start_index:end_index]
            
            if chunk:
                 yield chunk
                 await asyncio.sleep(0.005) 
            else:
                 break # Tr√°nh chunk r·ªóng n·∫øu logic c·∫Øt kh√¥ng ho√†n h·∫£o
        
        self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üîä [TTS] Ho√†n t·∫•t t·∫°o lu·ªìng audio.", color="purple")


# ==================== RTC INTEGRATION PROCESSOR =====================

class RTCStreamProcessor:
    def __init__(self, log_callback: Optional[Callable] = None):
        def default_log(message, color=None):
            if log_callback is None:
                print(f"[{time.strftime('%H:%M:%S')}] [LOG] {message}")
        
        self._log = log_callback if log_callback else default_log
        self._asr_client = ASRServiceMock(self._log)
        self._tts_client = TTSServiceMock(self._log)

    async def _record_stream(self, 
                             audio_input_stream: AsyncGenerator[bytes, None],
                             record_file: Path) -> AsyncGenerator[bytes, None]:
        """Ghi √¢m stream ƒë·∫ßu v√†o v√†o file v√† YIELD c√°c chunk ƒë·ªÉ truy·ªÅn cho ASR."""
        
        self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üíæ [Recorder] B·∫Øt ƒë·∫ßu ghi √¢m ƒë·∫ßu v√†o v√†o: {record_file.name}", color="orange")
        
        with wave.open(str(record_file), 'wb') as wf:
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(2) 
            wf.setframerate(SAMPLE_RATE)
            
            # ‚ö†Ô∏è V√≤ng l·∫∑p n√†y ƒë√£ ƒë∆∞·ª£c kh·∫Øc ph·ª•c l·ªói NoneType nh·ªù fix trong main_app.py
            async for chunk in audio_input_stream:
                wf.writeframes(chunk)
                yield chunk # Truy·ªÅn chunk sang b∆∞·ªõc ti·∫øp theo (ASR)

        self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üíæ [Recorder] Ho√†n t·∫•t ghi √¢m: {record_file.name}", color="orange")


    async def handle_rtc_session(self, 
                                 audio_input_stream: AsyncGenerator[bytes, None], 
                                 session_id: str) \
                                 -> AsyncGenerator[Tuple[bool, Any], None]:
        """
        X·ª≠ l√Ω phi√™n RTC: Ghi √¢m ƒë·∫ßu v√†o -> ASR/NLU -> TTS.
        Tr·∫£ v·ªÅ lu·ªìng audio TTS v√† lu·ªìng text metadata.
        Output Format: (is_audio: bool, data: Any)
        """
        self._log(f"[{_dt.now().strftime('%H:%M:%S')}] ‚ñ∂Ô∏è [RTC] B·∫Øt ƒë·∫ßu phi√™n RTC...", color="cyan")
        
        # 1. Ghi √¢m ƒë·∫ßu v√†o v√† t·∫°o stream m·ªõi
        record_file = RECORDING_DIR / f"{session_id}_input.wav"
        # Lu·ªìng n√†y v·ª´a ghi √¢m v·ª´a truy·ªÅn chunk cho ASR
        recording_and_passing_stream = self._record_stream(audio_input_stream, record_file)

        # 2. X·ª≠ l√Ω ASR
        asr_stream = self._asr_client.transcribe(recording_and_passing_stream)
        full_transcript = ""
        async for partial_text in asr_stream:
            full_transcript += partial_text
        
        # 3. NLU/Response Logic (Mock)
        response_text = "T√¥i kh√¥ng hi·ªÉu y√™u c·∫ßu c·ªßa b·∫°n. Vui l√≤ng n√≥i l·∫°i."
        if full_transcript and "ƒë∆°n h√†ng" in full_transcript.lower():
            response_text = "ƒê√£ t√¨m th·∫•y y√™u c·∫ßu ƒë·∫∑t ƒë∆°n h√†ng. B·∫°n mu·ªën s·∫£n ph·∫©m n√†o?"
        
        self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üß† [NLU] Transcript: '{full_transcript[:30]}...' -> Response: '{response_text[:30]}...' (File: {record_file.name})", color="green")

        # YIELD TEXT METADATA ƒê·ªÇ GHI V√ÄO CHAT BOX
        # Format: (False, {'user_text': transcript, 'bot_text': response})
        yield (False, {"user_text": full_transcript, "bot_text": response_text})

        # 4. TTS v√† Tr·∫£ v·ªÅ Lu·ªìng Audio
        tts_audio_stream = self._tts_client.synthesize(response_text)
        
        # YIELD AUDIO CHUNKS
        # Format: (True, audio_chunk_bytes)
        async for chunk in tts_audio_stream:
             yield (True, chunk) 
        
        self._log(f"[{_dt.now().strftime('%H:%M:%S')}] üèÅ [RTC] Phi√™n ho√†n t·∫•t.", color="cyan")